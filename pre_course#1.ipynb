{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pre-course.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNQ1j/COMYkds/bslihDAFs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kyg1225/learning/blob/master/pre_course%231.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v98zJ_ONeaiR",
        "colab_type": "text"
      },
      "source": [
        "#인공지능 사례 분석 - 1주차 과제\n",
        "현재 시중에는 다양한 분야에서 인공지능을 사용하고 았다. 그중에서도 언어, 음성, 이미지,자율주행에 대해 분석해 보자."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YxxvkzQHUYwx",
        "colab_type": "text"
      },
      "source": [
        "##언어분야   \n",
        "과거에는 '통계 기반 기계번역(SMT)' 방식으로, 단어나 문맥을 제대로 파악하지 못해 오역되거나 해석할 수 없어, 자연스럽지 않은 번역의 티가 많이 났었다. 하지만 지금은 '인공 신경망(NMT)' 기반으로 기술이 발달하면서 실생활에서 활용될 만한 수준의 통 번역본은 물론 더욱더 인간의 언어에 가까운 말투로 문장을 번역해 주고 있다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0pZb_FmYHLup",
        "colab_type": "text"
      },
      "source": [
        ">### 1. LG CNS, 한국어 질문에 대한 데이터 셋 공개\n",
        " LG CNS가 공개한 'KorQuAD'는 1,550개의 Wikipedia Article에 대해 10,649건의 하위 문단과 크라우드 소싱을 통해 제작한 질의응답 등 한국어 표준테이터 10만개 가량이 단겨 AI가 장문의 답변을 하는데 활용될 전망이다. 무엇보다 그간 AI학습에 필요한 영어 표준 데이터는 다양한 자료들이 있었지만, 국내에는 한국어 표준 데이터가 거의 존재하지 않았다는 점에서 향후 한국어를 활용한 AI 서비스가 발전할 수 있는 기반이 될 것이다. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3qqBrxUpKLQC",
        "colab_type": "text"
      },
      "source": [
        ">### 2. 두 손이 자유로운 번역, 타임케틀, __'WT2'__   \n",
        "타임케틀의 'WT2'는 동시 통역이 가능한 무선 이어폰이다. 전 세계 36개 언어를 지원하는 WT2는 통역이 필요한 순간에 버튼을 누를 필요가 없다, 바로 번역 과정이 전용 앱과 연동되기 때문엔데, 이어폰 장착 후 자신의 언어로 말하면 상대방에게 번역된 언너가 음성으로 전달된다. 이어폰을 장착하는 것이 여의치 않을 때도 이어폰에 탑재된 마이크에 문장을 전닿라면 전용 앱이 이를 텍스트로 번역하고 읽어준다. 하지만 아직은 문자의 동시통역에 있어 15초의 간격이 필요하며, 약 5초간의 지연이 발생한다고 한다. 그래도 기존에 사람이 사람에게서 문장을 듣고, 직접 검색하고, 번역을 해보던 순간에 비해서라면 훨씬 큰 발전을 이뤄낸 것이다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ZBnex3TUZEL",
        "colab_type": "text"
      },
      "source": [
        "##음성분야   \n",
        "음성인식 기술은 고유의 목소리 뿐만 아니라 수많은 단어까지 모두 인식하고 처리할 수 있어야 한다. 처음에는 단순한 명령 정도만 알아듣는 음성비서로 시작했던 기술은 이후에 더욱 다양한 분야에 적용되면서 빠르게 발전하고 있다. 말 한마디로 날씨 예보는 물론 좋아하는 음악, 사고싶은 물건에 대한 쇼핑정보를 알아낼 수 있을정도로 음성인식 기술은 이미 우리 생활에 깊이 스며들었고, 일상 속에서 널리 사용되고 있다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q9r5dRTcaQB2",
        "colab_type": "text"
      },
      "source": [
        ">### 1. TV\n",
        "LG 올레드 TV AI ThinQ는 __자연어 음성인식 기능__을 적용하여 매직 리모컨의 마이크 표시 버튼을 누르고 명령만 하면 말한마디로 __'인공지능 맞춤 검색'__부터 __'인공지능 TV 제어', '인공지능 영상 사운드 모드 조정'__까지 가능하다. 뿐만 아니라 스스로 최적의 화질을 찾아 주는 독자 개발 인공지능 화질엔진인 __'알파9'__탑재로 보다 완벽한 화질까지 즐길 수 있다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OiBrQVitfPKX",
        "colab_type": "text"
      },
      "source": [
        "> ### 2. 에어컨\n",
        "자체 인공지능 플랫폼인 딥씽큐(Deep ThinQ)를 탑제한 LG 휘센 씽큐 에어컨은 사용자의 언어를 스스로 학습한다. 정해진 명령어뿐 아니라 \"더워\" \"추워\"와 같은 사용자의 자연스러운 반응도 인식해 작동 여부를 먼저 제안한다. 또한 사용자가 다양한 사투리를 사용하는 경우를 감안해 각 지역마다 다른 억양 데이터도 확보했다. 에어컨이 스스로 사용자의 언어 사용패턴을 학습하는 원리이기 때문에 사투리도 쓰면 쓸수록 인식률이 높아진다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pN_KQPt-gZk7",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "> ### 3. 세탁기\n",
        "LG 트롬 씽큐 세탁기는 음성만으로 손쉽게 전원을 켜고 끄거나 세탁 코스, 옵션을 설정할 수 있게 된다. 제품을 동작하는 데서 더 나아가 세탁기의 상태를 진단한 결과나 세탁 방법을 음성으로 알려주는 것이다. 이뿐만이 아니라 고객의 제품 사용 패턴과 날씨 정보를 학습해 사용자에게 최적화된 세탁 옵션을 알아서 설정해주는 '스마트케어' 기능을 탑재했다. 사용자가 가장 많이 사용하는 옵션을 학습해서 반영하고, 날씨에 따라 해당 설정을 스스로 변경해준다. 예를 들어 비가 오는 날은 탈수 강도를 높이고, 미세먼지가 많은 날엔 강력 세탁 코스를 선택하며 헹굼 횟수를 늘리는 식입니다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OUfLTcT2UZNy",
        "colab_type": "text"
      },
      "source": [
        "## 이미지 분야\n",
        "음성인식 기술에서 한 단계 더 나아간 기술로 사물을 보고 스스로 인식하는 'AI 이미지 분석 기술'은 **이미지 분석 분야**에서 각광받고 있다.   \n",
        "딥러닝(Deep Learning)을 통해 **사람의 시각처럼 높은 정확도와 다양한 사물인식**이 가능한 AI이미지 분석으로 한단계 진화햐여 등장했다. 이 기술을 이용한 서비스는 다음과 같은 것들이 있다.  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CX8H0j0pUsc7",
        "colab_type": "text"
      },
      "source": [
        "> ### 1. **구글 포토**\n",
        "사진 서비스는 이미지들을 여러 그룹에 분석, 정리할 수 있으며 바닷가, 스카이라인, 토론토의 눈보라와 같은 기능을 식별할 수 있다. 응용 프로그햄의 검색 창에서는 3가지 분류(인물, 장소, 물건)로 사진 그룹에 대한 검색이 사용자에게 표시된다. 이 서비스는 비슷한 얼굴에 대한 사진을 분석하고 인뭏 분류에서는 이들을 한데 묶어준다. 나이가 듦에 따라서도 얼굴을 찾을 수 있다. 장소 분류는 geo tagging데이터를 사용하지만 주요 랜드마크를 분석함으로써 오래된 사진의 장소를 결정할 수도 있다. 물건 분류는 생일, 건물, 고양이, 콘서트, 음식, 졸업, 포스터, 스크린샷 등의 물건에 대하 사진을 처리할 수 있다. \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kVNwuVgjoztN",
        "colab_type": "text"
      },
      "source": [
        "  >### 2.  **구글 렌즈**\n",
        "전화의 카메라를 물체에 갖다대면 구글 렌즈는 물체의 식별을 시도하고 관련 검색 결과와 정보를 표시한다. 구글 렌즈는 구글 초토와 구글 어시스턴트 앱과도 연동이 된다. 렌즈는 더 진보화된 딥 러닝 루틴을 사용하며 이는 빅스비(신형 삼성 스마트폰과 연동), 이미지 분석 툴셋(구글 플레이를 통해 이용 가능) 등의 다른 앱들과 비슷하다. 인공 신경망을 사용하여 물체, 랜드마크를 감지하고 식별하여 광학 문자 인식(OCR) 정확도를 개선한다,\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EWdgbbOapBEB",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "> ### 3.  **이미지 기반 상품 추천 서비스** -  _오드 컨셉_    \n",
        "오드 컨셉이 개발한 기술은 AI기반 픽셀광고이다. 상품 추천은 철저히 AI가 '이미지'를 분석해 나온다. 하루 1000만개 이상의 상품 데이터를 머신러닝 기반으로 분석해 상품을 12가지 타입, 94개의 속성으로 분류한다. 이 서비스가 상요화 되면 다음과 같은 일을 겪을 수 있다.     \n",
        "\n",
        "\n",
        "\n",
        ">> _# 직장인 A씨는 스마트폰으로 좋아하는 가수 B씨 기사를 보던 중 B씨가 입고있는 점퍼가 맘에 쏙 들었다. 막연히 온라인 쇼핑몰에 들아가 검색하려던 순간 A씨는 깜짝 놀랐다. 기사 이미지 바로 밑에 온라인에서 판매중인 유사 점퍼 이미지가 올라와 있던 것._\n",
        "\n",
        ">>_# 온라인 쇼핑몰에서 목도리를 고르던 C씨는  갑자기 어젯밤 프로 농구 결과가 궁금해 뉴스를 찾아 갔다. 기사를 한참 읽어내려가던 C씨는 중간에 쇼핑몰에서 검색하던 제품과 유사한 목도리가 나열되어 있는 것을 확인했다._\n",
        "\n",
        ">이 서비스를 인터넷 쇼핑몰과 오픈마켓 업체 1곳을 통해 각 23일과 10일간 테스트 했다. 뉴스사이트로 부타 유입돼 판매까지 이어진 매출 규모가 1억 3000천 만원과 8400만원이었다. 광고비는 100만원대 후반인것을 감안하면 '광고대비 매출액'이 7260%와 5050%에 달한 셈이다.   \n",
        "   \n",
        "\n",
        " \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IYypdoqQpGBH",
        "colab_type": "text"
      },
      "source": [
        ">### 4. **수아키트** - _수아랩_   \n",
        "수아키트는 수아랩의 대표적인 제품이다. 정상제품의 사진과 불량품의 사진을 AI가 스스로 학습해 불량품을 쉽게 판별해낼 수 있다. 기존에는 머신비전을 사용하더라도 엔지니어가 일일이 수동으로 결함들을 입력해줘야 했는데, 이 제품은 사진만으로도 학습 데이터를 쉽게 입력할 수 있어 효율적이다. 육안 검사 대신 AI를 활용하는 데도 5픽셀(1.33mm) 이하의 작은 불량까지 걸러낼 수 있다.  이 제품을 통해 전통 제조기업들은 수작업으로 할 수밖에 없었던 품질관리(Quality Control, QC) 과정의 불량률을 낮출 수 있다. 이전까지는 머신비전 기술을 공장에 적용하기 위해서 드는 구축 비용이 사업을 확장하는 데 있어 걸림돌이었다. 하지만 현재는 5G통신 기술과 클라우드를 이용해 비용을 대거 줄일 수 있어 머신비전 기술을 통해 시장을 선도할 것이다. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O8__Sj09pPdS",
        "colab_type": "text"
      },
      "source": [
        ">### 5. **무인 스토어**   \n",
        "\n",
        ">>* _아마존고(Amazon go)_   \n",
        "아마존고는 세계 최초 무인 매장으로 아마존(Amazon)에서 운영하는 슈퍼마켓이다. 계산대와 계산원이 없으며 인공지능과 머신러닝, 컴퓨터 비전 등의 기술을 활용하고 있다. 매장을 이용하기 위해서는 스마트폰 앱을 다운로드 해야하며 이 애플리케이션을 키고 QR코드를 출입문에 대면 입장이 가능하다. 천장에 달린 카메라와 블랙박스 센서는 소비자가 집어든 상품을 자동으로 감지하고 소비자는 별도의 계산 과정 없이 매장을 나간다. 매장을 나간 소비자는 앱에 등록된 결제수단으로 비용이 자동 결제된다. 하지만 인공지능이 잘 판독할수 있도록 하기위해 매장에 수용가능한 인원수를 50명 내외로 제한하고 있다.  \n",
        "\n",
        ">>*   _이마트 에브리데이 스마트 점포_   \n",
        "이마트 에브리데이 스마트 점포는 우리나라의 무인 편의점이다. 이곳에 입장하기 위해서는 바코드 인증 후 스피드 게이트를 통과해야한다. 원하는 물건을 고르고 스마트폰에서 전용 앱인 SSG PAY에 접속해서 제품에 달려있는 QR코드를 찍으면 모바일 장바구니에 해당 제품이 담긴다. 결제를 완료하면 모바일 결제 영수증을 스마트 게이트에 찍어서 나오면 된다. 아마존고에 비해서 다소 번거로울 수 있는데 이렇게 애플리케이션 이용이 어려운 사람은 별도로 마련된 셀프 계산대를 이용하면 된다.    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7F2-2NOipXaA",
        "colab_type": "text"
      },
      "source": [
        "## 자율주행 분야\n",
        "자율주행이란 운전자가 직접 조작하지 않아도 자동차가 주행환경을 이식해 위험을 판단하고 주행경로를 계획해 스스로 운전하는 자동차로 감지시스템, 중앙제어장치, 액츄에이터 등으로 구성되며, 로봇 및 컴퓨터공학, GPS, 정밀센서, 전자제어 등 첨단기술을 필요로한다.  자율주행 기술은 자율화된 수준에 따라 크게 5단계로 나눌 수 있다. 주행보조 장치가 전혀 없는 0단계 부터 운전자의 개입이 전혀 없고 모든 환경에서 자율주행이 가능한 5단계 까지 분류되어 있다. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o3plqoiuoBOC",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "> ### 1. 웨이모(Waymo)   \n",
        "웨이모는 4단계 자율주행 자동차로 높은 자동화로 운전자는 특정 상황에만 개입하는 단계이다. 웨이모는 지난 2018년 12월 5일 미국 애리조나주 피닉스에서 세계 최초로 상용 자율주행차 서비스를 시작했다. 웨이모 자율차 앱을 가진 탑승자는 기존 차량 호출 서비스인 우버와 마찬가지로 스마트폰을 통해 차량을 호출해 탈 수 있게 됐다. 서비스 명의 '웨이모 원(Waymo One)'으로 정해졌다. 웨이모 자율차는 운전자의 핸들 또는 기기 작동없이 스스로 운전하지만, 프로그램이 오작동할 경우에 대비해 자사 엔지니어가 자율차 운전석에 앉아 상황을 모니터링하는 것으로 시범운행을 시작했다. \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NJToc06LuKZk",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "> ### 2. 우버(Uber)   \n",
        " 차량 공우 서비스 우버가 직접 개발한 자율 주행 기술을 적용한 차량에 손님을 태우고 영업을 시작했다. 우버의 고급 차량 서비스 우버X를 호출한 승객들을 대상으로 서비스를 시작했다. 우버는 2016년 6월에는 포드 세단을 개조한 테스트 차량의 도로 주행 테스트를 시작했고, 10월에는 실제 화물을 싣고 200km의 거리를 달려 안전하게 배송하는 데 성공했다. 그리고 12월 15일 부터 승객을 태우기 시작했다. 혹시모를 상황에 대비하는 보조 운전자가 탑승해 있고 뒷자석에는 현재 위치, 목적지, 음악 등을 확인하고 조작 할 수 있는 아이패드가 장착되어 있다. 현재는 볼보와 제휴해 개발한 'XC90' 자율 주행 자동차를 2022년 세계 13개 주요도시에 7만 5천대 출시를 목표로 하고 있다고 한다.  "
      ]
    }
  ]
}
